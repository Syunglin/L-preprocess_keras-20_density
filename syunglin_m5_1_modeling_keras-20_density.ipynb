{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /tmp/data/\n",
    "! mkdir -p /tmp/data/zipped/labeled/\n",
    "! mkdir -p /tmp/data/unzipped/labeled/train/ok\n",
    "! mkdir -p /tmp/data/unzipped/labeled/train/ng\n",
    "! mkdir -p /tmp/data/unzipped/labeled/test/ok\n",
    "! mkdir -p /tmp/data/unzipped/labeled/test/ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/NG-201808.zip to ../../../../../tmp/data/zipped/labeled/NG-201808.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/OK-1.zip to ../../../../../tmp/data/zipped/labeled/OK-1.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/OK-2.zip to ../../../../../tmp/data/zipped/labeled/OK-2.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/OK-3.zip to ../../../../../tmp/data/zipped/labeled/OK-3.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/NG-2.zip to ../../../../../tmp/data/zipped/labeled/NG-2.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/NG-4.zip to ../../../../../tmp/data/zipped/labeled/NG-4.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/NG-synthetic.zip to ../../../../../tmp/data/zipped/labeled/NG-synthetic.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/NG-1.zip to ../../../../../tmp/data/zipped/labeled/NG-1.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/NG-5.zip to ../../../../../tmp/data/zipped/labeled/NG-5.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/OK-4.zip to ../../../../../tmp/data/zipped/labeled/OK-4.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/OK-5.zip to ../../../../../tmp/data/zipped/labeled/OK-5.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/NG-3.zip to ../../../../../tmp/data/zipped/labeled/NG-3.zip\n",
      "download: s3://fstech.tw/wafer_defect/data/zipped/labeled/OK-201808.zip to ../../../../../tmp/data/zipped/labeled/OK-201808.zip\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp s3://fstech.tw/wafer_defect/data/zipped/labeled/ /tmp/data/zipped/labeled/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -q -o /tmp/data/zipped/labeled/NG-1.zip -d /tmp/data/unzipped/labeled/train/ng\n",
    "! unzip -q -o /tmp/data/zipped/labeled/NG-2.zip -d /tmp/data/unzipped/labeled/train/ng/\n",
    "! unzip -q -o /tmp/data/zipped/labeled/NG-3.zip -d /tmp/data/unzipped/labeled/train/ng/\n",
    "! unzip -q -o /tmp/data/zipped/labeled/NG-4.zip -d /tmp/data/unzipped/labeled/train/ng/\n",
    "! unzip -q -o /tmp/data/zipped/labeled/NG-5.zip -d /tmp/data/unzipped/labeled/test/ng/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip -q -o /tmp/data/zipped/labeled/OK-1.zip -d /tmp/data/unzipped/labeled/train/ok\n",
    "! unzip -q -o /tmp/data/zipped/labeled/OK-2.zip -d /tmp/data/unzipped/labeled/train/ok/\n",
    "! unzip -q -o /tmp/data/zipped/labeled/OK-3.zip -d /tmp/data/unzipped/labeled/train/ok/\n",
    "! unzip -q -o /tmp/data/zipped/labeled/OK-4.zip -d /tmp/data/unzipped/labeled/train/ok/\n",
    "! unzip -q -o /tmp/data/zipped/labeled/OK-5.zip -d /tmp/data/unzipped/labeled/test/ok/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p /tmp/data/images/standard/labeled/train/ok\n",
    "! mkdir -p /tmp/data/images/standard/labeled/train/ng\n",
    "! mkdir -p /tmp/data/images/standard/labeled/test/ok\n",
    "! mkdir -p /tmp/data/images/standard/labeled/test/ng\n",
    "! mkdir -p /tmp/data/images/standard/labeled/augmented\n",
    "! mkdir -p /tmp/data/images/linearpolar/labeled/train/ok\n",
    "! mkdir -p /tmp/data/images/linearpolar/labeled/train/ng\n",
    "! mkdir -p /tmp/data/images/linearpolar/labeled/test/ok\n",
    "! mkdir -p /tmp/data/images/linearpolar/labeled/test/ng\n",
    "! mkdir -p /tmp/data/images/linearpolar/labeled/augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_defect_list(raw_text_path):\n",
    "    # Read file\n",
    "    f = open(raw_text_path)\n",
    "    lines = f.read()\n",
    "    \n",
    "    # Get only DefectList section of raw data\n",
    "    defect_list = [l.strip('\\n') for l in lines.split(';') if l.strip('\\n').startswith('DefectList')][0]\n",
    "\n",
    "    # Drop \"DefectList\" title, then split each row of DefectList into columns and convert to floats\n",
    "    columns = [np.array(l.strip(' ').split(' '), dtype=np.float64) for l in defect_list.split('\\n')[1:]]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    parsed = np.array(columns)\n",
    "    \n",
    "    return parsed\n",
    "\n",
    "def save_defect_standard(defect_array, output_dir, filename='out.png'):\n",
    "    if len(defect_array)>0:\n",
    "        # limit to test types 1 and 6 per client expertise\n",
    "        vals = np.array([[arr[1], arr[2], arr[8]] for arr in defect_array if arr[10] in [1,6]])\n",
    "\n",
    "        if len(vals)>0:\n",
    "            x = vals.T[0]\n",
    "            y = vals.T[1]\n",
    "            #s = vals.T[2] # get original dsize values\n",
    "            \n",
    "            wafer_size = 300000\n",
    "            dot_size = 2600\n",
    "            \n",
    "            # Reduce output image size by a specific factor\n",
    "            f = 1000\n",
    "            \n",
    "            im = Image.new('RGB', (int(wafer_size/f+1), int(wafer_size/f+1)), 'white')\n",
    "            draw = ImageDraw.Draw(im)\n",
    "\n",
    "            draw.ellipse([0, 0, wafer_size/f, wafer_size/f], 'white', 'black')\n",
    "\n",
    "            for i in range(len(x)):\n",
    "                cur_x = x[i]/f\n",
    "                cur_y = y[i]/f\n",
    "                x0 = cur_x-(0.5*dot_size/f)\n",
    "                y0 = cur_y-(0.5*dot_size/f)\n",
    "                x1 = cur_x+(0.5*dot_size/f)\n",
    "                y1 = cur_y+(0.5*dot_size/f)\n",
    "                draw.ellipse([x0, y0, x1, y1], 'black', 'black')\n",
    "\n",
    "            im.save(os.path.join(output_dir, filename))\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "def save_defect_linearpolar(defect_array, output_dir, filename='out.png', opacity=0.2):\n",
    "    if len(defect_array)>0:\n",
    "        # limit to test types 1 and 6 per client expertise\n",
    "        defects = np.array([[arr[1], arr[2]] for arr in defect_array if arr[10] in [1,6]])\n",
    "\n",
    "        if len(defects)>0:\n",
    "            x = defects.T[0]\n",
    "            y = defects.T[1]\n",
    "            #s = vals.T[2] # get original dsize values\n",
    "            \n",
    "            center = (150000,150000)\n",
    "\n",
    "            # Calculate distance of point to center\n",
    "            rho = np.sqrt((x-center[0])**2 + (y-center[1])**2)\n",
    "            # Calculate angle to point\n",
    "            theta = np.arctan2((y-center[1]), (x-center[0]))*(180/np.pi)\n",
    "            # Convert from (-180, 180] to [0, 360)\n",
    "            theta = np.array([t if t>=0 else (t+360) for t in theta])\n",
    "\n",
    "            # Start with base image with black background\n",
    "            im1 = Image.new('RGBA', (361, 361), (0,0,0,255))\n",
    "\n",
    "            # For each dot, add a little alpha to the original image\n",
    "            for i in range(len(rho)):\n",
    "                im2 = Image.new('RGBA', (361, 361), (0,0,0,0))\n",
    "                draw = ImageDraw.Draw(im2)\n",
    "                cur_x = theta[i]\n",
    "                cur_y = rho[i]*360/center[0]\n",
    "                x0 = cur_x-2\n",
    "                y0 = 360-cur_y-2\n",
    "                x1 = cur_x+2\n",
    "                y1 = 360-cur_y+2\n",
    "                draw.ellipse([x0, y0, x1, y1], (255,255,255,int(255*opacity)), None)\n",
    "                im1 = Image.alpha_composite(im1, im2)\n",
    "\n",
    "            # Convert this to 'L' mode from RGBA to save space\n",
    "            im1 = im1.convert('L')\n",
    "\n",
    "            im1.save(os.path.join(output_dir, filename))\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob('/tmp/data/unzipped/labeled/*/*/*.001'):\n",
    "    fname = f.split('/')[-1]\n",
    "    label = f.split('/')[-2]\n",
    "    train_or_test = f.split('/')[-3]\n",
    "    defects = parse_defect_list(f)\n",
    "    save_defect_standard(defects, \n",
    "                         '/tmp/data/images/standard/labeled/{}/{}'.format(train_or_test, label), \n",
    "                         '{}.png'.format(fname))\n",
    "    \n",
    "    save_defect_linearpolar(defects, \n",
    "                           '/tmp/data/images/linearpolar/labeled/{}/{}'.format(train_or_test, label), \n",
    "                           '{}.png'.format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3940\n",
      "4000\n",
      "1000\n",
      "989\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(len(glob('/tmp/data/images/linearpolar/labeled/train/ok/*.png')))\n",
    "print(len(glob('/tmp/data/images/linearpolar/labeled/train/ng/*.png')))\n",
    "print(len(glob('/tmp/data/images/linearpolar/labeled/test/ok/*.png')))\n",
    "print(len(glob('/tmp/data/images/linearpolar/labeled/test/ng/*.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0765cac23c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(300, 300, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "# Output\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "#multi_model = multi_gpu_model(model, gpus=gpu_count) # if multiple gpus on single system\n",
    "\n",
    "#adam = Adam()\n",
    "sgd = SGD(nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[categorical_accuracy])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7940 images belonging to 2 classes.\n",
      "Found 1989 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_datagen = ImageDataGenerator(    \n",
    "#    shear_range=0.2,\n",
    "    fill_mode='wrap',\n",
    "    height_shift_range=0.5,\n",
    "    width_shift_range=0.5,\n",
    "    vertical_flip=True, \n",
    "    horizontal_flip=True,\n",
    "#    rotation_range=360,\n",
    "    rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/tmp/data/images/linearpolar/labeled/train/',\n",
    "    save_to_dir='/tmp/data/images/linearpolar/labeled/augmented/',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=batch_size, \n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '/tmp/data/images/linearpolar/labeled/test/',\n",
    "        target_size=(300, 300),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  8/125 [>.............................] - ETA: 2:22 - loss: 0.7838 - categorical_accuracy: 0.5020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c2b2dff587b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     validation_steps=100)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 204\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0aa74afd68>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(ylim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
